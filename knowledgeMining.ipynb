{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deea231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 伪代码和概念结构\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_neo4j import Neo4jGraph\n",
    "\n",
    "# 1. 初始化模型和图数据库连接\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.2,  # 设置温度以控制输出的随机性\n",
    "    base_url=\"\",\n",
    "    api_key=\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0236b236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neo4jGraph用于后续直接写入图数据库\n",
    "graph = Neo4jGraph(\n",
    "    url=\"\", \n",
    "    username=\"neo4j\", \n",
    "    password=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97f4cc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 定义输出结构 (Pydantic Models) 和解析器\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class GazetteerInfo(BaseModel):\n",
    "    lake_name: str = Field(description=\"湖泊的名称\")\n",
    "    location: str = Field(description=\"湖泊所在的古代地名\")\n",
    "    gazetteer_source: str = Field(description=\"记载该湖泊的方志名称\")\n",
    "    content: str = Field(description=\"方志中关于该湖泊的原始记载内容\")\n",
    "\n",
    "class PoemInfo(BaseModel):\n",
    "    lake_name: str = Field(description=\"诗词中提到的湖泊名称\")\n",
    "    poem_name: str = Field(description=\"提到该湖泊的诗词名称\")\n",
    "    poem_full_text: str = Field(description=\"提到该湖泊的完整诗词内容\")\n",
    "\n",
    "# 支持多湖泊的输出结构\n",
    "class MultipleGazetteerInfo(BaseModel):\n",
    "    extractions: List[GazetteerInfo] = Field(description=\"从文本中提取的所有湖泊信息列表\")\n",
    "\n",
    "class MultiplePoemInfo(BaseModel):\n",
    "    extractions: List[PoemInfo] = Field(description=\"从文本中提取的所有诗词信息列表\")\n",
    "\n",
    "# 创建输出解析器 - 使用多湖泊解析器\n",
    "gazetteer_parser = PydanticOutputParser(pydantic_object=GazetteerInfo)\n",
    "poem_parser = PydanticOutputParser(pydantic_object=PoemInfo)\n",
    "\n",
    "# 多湖泊解析器\n",
    "multi_gazetteer_parser = PydanticOutputParser(pydantic_object=MultipleGazetteerInfo)\n",
    "multi_poem_parser = PydanticOutputParser(pydantic_object=MultiplePoemInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5eed69fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 开始从文件加载 Document 块: split_outputs_jsonl/processed_chunks2.jsonl ---\n",
      "--- 加载完成！成功从文件恢复了 432 个 Document 对象。 ---\n",
      "\n",
      "验证加载的第一个文档块:\n",
      "内容:\n",
      "---\n",
      "永乐大典卷之二千二百六十八【六模】\n",
      "湖\n",
      "巢湖\n",
      "《合肥志》\n",
      "在合肥县东南六十里。亦名焦湖。汉明帝十一年。漅湖出黄金。庐江太守以献。漅。音勦或曰勦湖。俗讹为焦湖。以其在巢县。亦曰巢湖。周围四百里。港（汊）...\n",
      "---\n",
      "元数据: {'source': './data_simplified.txt'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "# 1. 定义要读取的文件路径\n",
    "input_path = Path(\"split_outputs_jsonl/processed_chunks2.jsonl\")\n",
    "\n",
    "# 2. 准备一个空列表来存放加载后的 Document 对象\n",
    "loaded_documents: List[Document] = []\n",
    "\n",
    "print(f\"\\n--- 开始从文件加载 Document 块: {input_path} ---\")\n",
    "\n",
    "# 3. 检查文件是否存在\n",
    "if not input_path.exists():\n",
    "    print(f\"--- 错误：文件不存在 -> {input_path} ---\")\n",
    "else:\n",
    "    try:\n",
    "        # 以读取模式打开文件\n",
    "        with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            # 逐行读取文件\n",
    "            for line in f:\n",
    "                # a. 使用 json.loads 将每一行的 JSON 字符串解析为字典\n",
    "                data_record = json.loads(line)\n",
    "                \n",
    "                # b. 使用字典中的数据重新创建 Document 对象\n",
    "                doc = Document(\n",
    "                    page_content=data_record[\"page_content\"],\n",
    "                    metadata=data_record[\"metadata\"]\n",
    "                )\n",
    "                \n",
    "                # c. 将创建好的 Document 对象添加到列表中\n",
    "                loaded_documents.append(doc)\n",
    "\n",
    "        print(f\"--- 加载完成！成功从文件恢复了 {len(loaded_documents)} 个 Document 对象。 ---\")\n",
    "\n",
    "        # 验证一下加载回来的第一个 Document\n",
    "        if loaded_documents:\n",
    "            print(\"\\n验证加载的第一个文档块:\")\n",
    "            first_doc = loaded_documents[0]\n",
    "            print(f\"内容:\\n---\\n{first_doc.page_content[:100]}...\\n---\")\n",
    "            print(f\"元数据: {first_doc.metadata}\")\n",
    "            \n",
    "    except (IOError, json.JSONDecodeError) as e:\n",
    "        print(f\"--- 读取或解析文件时发生错误: {input_path}. 错误详情: {e} ---\")\n",
    "\n",
    "docs = loaded_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4e3780a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 创建 Few-shot 提示\n",
    "# 方志的 Few-shot 示例\n",
    "gazetteer_examples = [\n",
    "    {\n",
    "        \"input\": \"《大清一统志》：西湖在杭州府城西，周三十里。其水甘澄，能疗疾。苏轼尝官此，有诗纪其事。\",\n",
    "        \"output\": MultipleGazetteerInfo(\n",
    "            extractions=[GazetteerInfo(\n",
    "                lake_name=\"西湖\",\n",
    "                location=\"杭州府\",\n",
    "                gazetteer_source=\"大清一统志\",\n",
    "                content=\"西湖在杭州府城西，周三十里。其水甘澄，能疗疾。苏轼尝官此，有诗纪其事。\"\n",
    "            )]\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"《太平寰宇记》：洞庭湖在岳州之南，方圆八百里，其气势浩瀚，为天下之冠。鄱阳湖在饶州，纵广三百三十里。\",\n",
    "        \"output\": MultipleGazetteerInfo(\n",
    "            extractions=[\n",
    "                GazetteerInfo(\n",
    "                    lake_name=\"洞庭湖\",\n",
    "                    location=\"岳州\",\n",
    "                    gazetteer_source=\"太平寰宇记\",\n",
    "                    content=\"洞庭湖在岳州之南，方圆八百里，其气势浩瀚，为天下之冠。\"\n",
    "                ),\n",
    "                GazetteerInfo(\n",
    "                    lake_name=\"鄱阳湖\",\n",
    "                    location=\"饶州\",\n",
    "                    gazetteer_source=\"太平寰宇记\",\n",
    "                    content=\"鄱阳湖在饶州，纵广三百三十里。\"\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    }\n",
    "]\n",
    "\n",
    "# 诗词的 Few-shot 示例\n",
    "poem_examples = [\n",
    "    {\n",
    "        \"input\": \"望洞庭湖赠张丞相 - 孟浩然\\n八月湖水平，涵虚混太清。气蒸云梦泽，波撼岳阳城。\",\n",
    "        \"output\": MultiplePoemInfo(\n",
    "            extractions=[PoemInfo(\n",
    "                lake_name=\"洞庭湖\",\n",
    "                poem_name=\"望洞庭湖赠张丞相\",\n",
    "                poem_full_text=\"八月湖水平，涵虚混太清。气蒸云梦泽，波撼岳阳城。\"\n",
    "            )]\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"饮湖上初晴后雨 - 苏轼\\n水光潋滟晴方好，山色空蒙雨亦奇。欲把西湖比西子，淡妆浓抹总相宜。\\n又题\\n朝曦迎客艳重冈，晚雨留人入醉乡。此意自佳君不会，一杯当属水仙王。-- 此诗亦咏西湖\",\n",
    "        \"output\": MultiplePoemInfo(\n",
    "            extractions=[\n",
    "                PoemInfo(\n",
    "                    lake_name=\"西湖\",\n",
    "                    poem_name=\"饮湖上初晴后雨\",\n",
    "                    poem_full_text=\"水光潋滟晴方好，山色空蒙雨亦奇。欲把西湖比西子，淡妆浓抹总相宜。\"\n",
    "                ),\n",
    "                PoemInfo(\n",
    "                    lake_name=\"西湖\",\n",
    "                    poem_name=\"又题\",\n",
    "                    poem_full_text=\"朝曦迎客艳重冈，晚雨留人入醉乡。此意自佳君不会，一杯当属水仙王。\"\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    }\n",
    "]\n",
    "\n",
    "# 创建 Few-shot 提示模板\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"输入:\\n{input}\\n输出:\\n{output}\"\n",
    ")\n",
    "\n",
    "# 方志的 Few-shot 提示\n",
    "gazetteer_prompt = FewShotPromptTemplate(\n",
    "    examples=gazetteer_examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"输入:\\n{input}\\n输出:\",\n",
    "    input_variables=[\"input\"],\n",
    "    example_separator=\"\\n\\n\",\n",
    "    prefix=\"\"\"\n",
    "    你是一个专门从古代文献中提取一个或多个湖泊信息的专家。\n",
    "    注意区分湖的别名和本名,区分方志和诗词，只保留本名。\n",
    "    如果不是文献方志，如诗词等，请不要提取，返回空列表。\n",
    "    如果文中提到多个湖泊，且这些湖泊不是同一湖泊的别名，请提取所有湖泊信息。\n",
    "    如果是文献方志，请根据以下格式提取信息：\\n{format_instructions}\n",
    "    \"\"\",\n",
    "    partial_variables={\"format_instructions\": multi_gazetteer_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "# 诗词的 Few-shot 提示\n",
    "poem_prompt = FewShotPromptTemplate(\n",
    "    examples=poem_examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"输入:\\n{input}\\n输出:\",\n",
    "    input_variables=[\"input\"],\n",
    "    example_separator=\"\\n\\n\",\n",
    "    prefix=\"\"\"你是一个专门从中国古典诗词中提取一个或多个湖泊信息的专家。\n",
    "    注意区分湖的别名和本名，区分方志和诗词，只保留本名。\n",
    "    如果不是诗词，如方志等，请不要提取，返回空列表。\n",
    "    如果文中提到多个湖泊，且这些湖泊不是同一湖泊的别名，请提取所有湖泊信息。\n",
    "    如果是诗词，请根据以下格式，请根据以下格式提取信息：\\n{format_instructions}\n",
    "    \"\"\",\n",
    "    partial_variables={\"format_instructions\": multi_poem_parser.get_format_instructions()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5d806bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 构建处理链\n",
    "gazetteer_chain = gazetteer_prompt | llm | multi_gazetteer_parser\n",
    "poem_chain = poem_prompt | llm | multi_poem_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7152f0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "诗词提取结果: extractions=[]\n",
      "方志提取结果: extractions=[GazetteerInfo(lake_name='巢湖', location='合肥县', gazetteer_source='合肥志', content='在合肥县东南六十里。亦名焦湖。汉明帝十一年。漅湖出黄金。庐江太守以献。漅。音勦或曰勦湖。俗讹为焦湖。以其在巢县。亦曰巢湖。周围四百里。港（汊）大小三百六十。占合肥。舒城。巢县。庐江。四邑之境。')]\n"
     ]
    }
   ],
   "source": [
    "poem_res=poem_chain.invoke({\"input\":docs[0].page_content})\n",
    "gazetteer_res=gazetteer_chain.invoke({\"input\": docs[0].page_content})\n",
    "\n",
    "print(\"诗词提取结果:\", poem_res)\n",
    "print(\"方志提取结果:\", gazetteer_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "70a9d995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 阶段一：开始并发提取方志和诗词信息... ---\n",
      "  -> 正在并发处理方志链...\n",
      "  -> 方志链处理完成，耗时: 88.73 秒\n",
      "  -> 正在并发处理诗词链...\n",
      "  -> 诗词链处理完成，耗时: 30.02 秒\n",
      "\n",
      "--- 阶段二：开始聚合处理结果，准备写入数据库... ---\n",
      "  [警告] 诗词提取失败 (块 130): Invalid json output: ```\n",
      "{\"extractions\":[PoemInfo(lake_name='丰湖', poem_name='丰湖诗', poem_full_text='小米侍郎生较晚，龙眠居士远离呼。\\n不知若个丹青手，能冩微澜玉塔图？\\n岷峨一老古来少，杭颕二湖天下无。\\n帝恐先生晚牢落，南迁犹得管丰湖。\\n作桥聊结众生縁，不计全家落瘴烟。\\n内翰翻身脱犀带，黄金劝妇助金钱。')]}\n",
      "```\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
      "  -> 聚合完成：准备写入 540 条方志信息和 64 条诗词信息。\n",
      "\n",
      "--- 阶段三：开始批量写入数据到图数据库... ---\n",
      "  -> 成功批量写入 540 条方志信息。\n",
      "  -> 成功批量写入 64 条诗词信息。\n",
      "\n",
      "所有文档处理和入库操作已全部完成。\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# --- 阶段一：并发提取 ---\n",
    "print(\"--- 阶段一：开始并发提取方志和诗词信息... ---\")\n",
    "\n",
    "# 准备所有链的输入\n",
    "# content_chunk 来源于我们之前分割好的 Document 对象的 page_content\n",
    "inputs = [{\"input\": doc.page_content} for doc in docs]\n",
    "concurrency_config = {\"max_concurrency\": 10} # 设置合理的并发上限\n",
    "\n",
    "# 并发调用方志链\n",
    "print(\"  -> 正在并发处理方志链...\")\n",
    "start_time = time.time()\n",
    "gazetteer_results = gazetteer_chain.batch(\n",
    "    inputs, \n",
    "    config=concurrency_config, \n",
    "    return_exceptions=True\n",
    ")\n",
    "print(f\"  -> 方志链处理完成，耗时: {time.time() - start_time:.2f} 秒\")\n",
    "\n",
    "# 并发调用诗词链\n",
    "print(\"  -> 正在并发处理诗词链...\")\n",
    "start_time = time.time()\n",
    "poem_results = poem_chain.batch(\n",
    "    inputs, \n",
    "    config=concurrency_config, \n",
    "    return_exceptions=True\n",
    ")\n",
    "print(f\"  -> 诗词链处理完成，耗时: {time.time() - start_time:.2f} 秒\")\n",
    "\n",
    "\n",
    "# --- 阶段二：数据聚合 ---\n",
    "print(\"\\n--- 阶段二：开始聚合处理结果，准备写入数据库... ---\")\n",
    "\n",
    "gazetteer_data_for_db = []\n",
    "for i, result in enumerate(gazetteer_results):\n",
    "    if isinstance(result, Exception) or not result.extractions:\n",
    "        # 如果调用出错或模型未能提取任何信息，则跳过\n",
    "        if isinstance(result, Exception):\n",
    "            print(f\"  [警告] 方志提取失败 (块 {i+1}): {result}\")\n",
    "        continue\n",
    "    # 将 Pydantic 对象转换为字典，方便后续作为参数传递\n",
    "    for extraction in result.extractions:\n",
    "        gazetteer_data_for_db.append(extraction.model_dump())\n",
    "\n",
    "poem_data_for_db = []\n",
    "for i, result in enumerate(poem_results):\n",
    "    if isinstance(result, Exception) or not result.extractions:\n",
    "        if isinstance(result, Exception):\n",
    "            print(f\"  [警告] 诗词提取失败 (块 {i+1}): {result}\")\n",
    "        continue\n",
    "    for extraction in result.extractions:\n",
    "        poem_data_for_db.append(extraction.model_dump())\n",
    "\n",
    "print(f\"  -> 聚合完成：准备写入 {len(gazetteer_data_for_db)} 条方志信息和 {len(poem_data_for_db)} 条诗词信息。\")\n",
    "\n",
    "\n",
    "# --- 阶段三：批量写入图数据库 ---\n",
    "print(\"\\n--- 阶段三：开始批量写入数据到图数据库... ---\")\n",
    "\n",
    "# 1. 批量写入方志数据\n",
    "if gazetteer_data_for_db:\n",
    "    # 使用 UNWIND 将列表展开，然后在数据库端进行循环处理\n",
    "    gazetteer_query = \"\"\"\n",
    "    UNWIND $data as row\n",
    "    MERGE (l:Lake {name: row.lake_name})\n",
    "    ON CREATE SET l.location = row.location\n",
    "    MERGE (g:Gazetteer {source: row.gazetteer_source})\n",
    "    ON CREATE SET g.content = row.content\n",
    "    MERGE (l)-[:MENTIONED_IN_GAZETTEER]->(g)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        graph.query(gazetteer_query, {\"data\": gazetteer_data_for_db})\n",
    "        print(f\"  -> 成功批量写入 {len(gazetteer_data_for_db)} 条方志信息。\")\n",
    "    except Exception as e:\n",
    "        print(f\"  [错误] 批量写入方志信息失败: {e}\")\n",
    "\n",
    "# 2. 批量写入诗词数据\n",
    "if poem_data_for_db:\n",
    "    poem_query = \"\"\"\n",
    "    UNWIND $data as row\n",
    "    MERGE (l:Lake {name: row.lake_name})\n",
    "    MERGE (p:Poem {name: row.poem_name})\n",
    "    ON CREATE SET p.full_text = row.poem_full_text\n",
    "    MERGE (l)-[:MENTIONED_IN_POEM]->(p)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        graph.query(poem_query, {\"data\": poem_data_for_db})\n",
    "        print(f\"  -> 成功批量写入 {len(poem_data_for_db)} 条诗词信息。\")\n",
    "    except Exception as e:\n",
    "        print(f\"  [错误] 批量写入诗词信息失败: {e}\")\n",
    "\n",
    "\n",
    "print(\"\\n所有文档处理和入库操作已全部完成。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
